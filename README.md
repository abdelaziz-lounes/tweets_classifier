# NLP Tweets Classifier

## Overview
This project implements a deep learning-based NLP classifier to analyze tweets. The model is trained to classify tweets into different categories based on textual content. The notebook includes data preprocessing, model training, and evaluation steps.

## Features
- Utilizes deep learning techniques for tweet classification.
- Supports GPU acceleration for faster training.
- Leverages helper functions for efficient processing.
- Uses a dataset from Kaggle for training and testing.

## Requirements
To run this notebook, you need the following dependencies:
```markdown
- Python 3.x
- TensorFlow
- Pandas
- NumPy
- Matplotlib
- Scikit-learn
```
You can install the required packages using:
```sh
pip install tensorflow pandas numpy matplotlib scikit-learn
```

## Usage
1. **Check for GPU:** Ensure GPU is enabled for faster processing.
2. **Load Helper Functions:** Import required helper scripts.
3. **Download Dataset:** Get the tweet dataset from Kaggle.
4. **Preprocess Data:** Clean and prepare the text data.
5. **Train Model:** Train the deep learning model on the dataset.
6. **Evaluate Model:** Assess performance on test data.

## Dataset
The dataset used for this project is sourced from Kaggle. You may need a Kaggle account to download it.

## Running the Notebook
```markdown
1. Open Google Colab or Jupyter Notebook.
2. Upload the dataset if necessary.
3. Run each cell sequentially to execute the workflow.
```

## Acknowledgments
- The dataset is taken from Kaggle : https://www.kaggle.com/c/nlp-getting-started/data

